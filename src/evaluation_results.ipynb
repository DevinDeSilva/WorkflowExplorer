{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4abe883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:37 - INFO - src.explorer_updates -   Loading .env file from: /home/desild/work/research/chatbs/v2/.env\n",
      "12/01/2025 10:30:37 - INFO - src.explorer_updates -   Loading config: /home/desild/work/research/chatbs/v2/prov.config.yaml\n",
      "12/01/2025 10:30:37 - INFO - src.explorer_updates -   Loading metadata: /home/desild/work/research/chatbs/v2/data/workflow/10_sample_graph/chatbs_sample_metadata.json\n",
      "12/01/2025 10:30:37 - INFO - src.explorer_updates -   Initializing GraphManager...\n",
      "12/01/2025 10:30:37 - INFO - src.explorer_updates -   Graph loaded with 24073 triples.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import yaml\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from dotenv import load_dotenv\n",
    "from functools import partial\n",
    "from rdflib import Graph, Literal, URIRef\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import dycomutils as common_utils\n",
    "from typing import List, Dict, Any, Optional, Set, Tuple, DefaultDict\n",
    "import openai\n",
    "import ollama\n",
    "import random\n",
    "\n",
    "sys.path.append(\"/home/desild/work/research/chatbs/v2\")\n",
    "\n",
    "from src.utils.helpers import setup_logger\n",
    "from src.utils.parser import (\n",
    "    graph_query_to_sexpr,\n",
    "    is_inv_rel,\n",
    "    get_inv_rel,\n",
    "    graph_query_to_sparql,\n",
    ")\n",
    "from src.utils.kg import (\n",
    "    get_readable_relation,\n",
    "    get_readable_class,\n",
    "    get_non_literals,\n",
    "    get_nodes_by_class,\n",
    "    get_reverse_relation,\n",
    "    get_reverse_readable_relation,\n",
    "    prune_graph_query,\n",
    "    legal_class,\n",
    "    legal_relation,\n",
    ")\n",
    "from src.utils.arguments import Arguments\n",
    "from src.utils.sparql import (\n",
    "    SPARQLUtil,\n",
    "    get_freebase_label,\n",
    "    get_freebase_literals_by_cls_rel,\n",
    "    get_freebase_entid_lbl_by_cls,\n",
    ")\n",
    "from src.utils.maps import literal_map\n",
    "\n",
    "from transformers import set_seed\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers.util import semantic_search\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "from src.explorer_updates import Explorer, ExecutableProgram\n",
    "from src.utils.graph_manager import GraphManager, regex_add_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af888dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(\"/home/desild/work/research/chatbs\")\n",
    "V2_DIR = os.path.join(ROOT_DIR, \"v2\")\n",
    "\n",
    "run_info = {}\n",
    "_temp = {}\n",
    "gt = common_utils.serialization.load_json(os.path.join(\"evalutions\", \"GT\", \"questions_results.json\"))\n",
    "\n",
    "for k,v in gt.items():\n",
    "    _temp[v[\"question\"]] = v\n",
    "    \n",
    "gt = _temp\n",
    "for q in os.listdir(os.path.join(V2_DIR, \"logs/v3\")):\n",
    "    run_info[q.replace(\".json\", \"\")] = common_utils.serialization.load_json(os.path.join(V2_DIR, \"logs/v3\", q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6d9b651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(run_info.keys()) - set(gt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470bda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_from_markdown(text: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Extracts JSON from a markdown code block.\n",
    "    R: extract_json_from_markdown_stringr (simulated)\n",
    "    \"\"\"\n",
    "    match = re.search(r\"```json\\s*([\\s\\S]*?)\\s*```\", text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def return_json_formatted(model_response: str):\n",
    "    \"\"\"\n",
    "    Parses a JSON string, with retries for markdown blocks.\n",
    "    R: return_json_formatted\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # R: tryCatch({ fromJSON(model_response) })\n",
    "        return json.loads(model_response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        log.warning(\n",
    "            f\"Error parsing JSON (layer 1): {e}. Trying to extract from markdown.\"\n",
    "        )\n",
    "        try:\n",
    "            # R: tryCatch({ ... extract_json ... })\n",
    "            json_content = extract_json_from_markdown(model_response)\n",
    "            if json_content:\n",
    "                return json.loads(json_content)\n",
    "            else:\n",
    "                raise ValueError(\"No JSON markdown content extracted.\")\n",
    "        except Exception as e2:\n",
    "            # R: ... return(data.frame(question = NA, explanation = NA))\n",
    "            log.error(f\"Error in parsing JSON (layer 2): {e2}\")\n",
    "            # Return a list as the prompt expects, even on failure\n",
    "            return []\n",
    "\n",
    "def llm_chat(\n",
    "    system_prompt: str,\n",
    "    user_prompt: str,\n",
    "    model_version: str,\n",
    "    structured_output: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Sends a chat request to an OpenAI-compatible API.\n",
    "    R: llm_chat\n",
    "    \"\"\"\n",
    "    client = None\n",
    "    # R: if ((startsWith(model_version, \"gpt-\")) || (startsWith(model_version, \"o1-\")))\n",
    "    if model_version.startswith(\"gpt-\") or model_version.startswith(\"o1-\"):\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY not set in .env file\")\n",
    "        client = openai.OpenAI(api_key=api_key)\n",
    "    else:\n",
    "        # R: base_url = \"http://idea-llm-01.idea.rpi.edu:5000/v1/\"\n",
    "        client = openai.OpenAI(\n",
    "            base_url=\"http://idea-llm-01.idea.rpi.edu:5000/v1/\",\n",
    "            api_key=os.getenv(\n",
    "                \"LOCAL_LLM_API_KEY\", \"no-key-needed\"\n",
    "            ),  # Add your local key to .env if needed\n",
    "        )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    chat_params = {\"model\": model_version, \"messages\": messages}\n",
    "\n",
    "    # R: if (!is.null(structured_output))\n",
    "    if structured_output:\n",
    "        log.info(\"Requesting structured (JSON) output from LLM.\")\n",
    "        # This is the modern way to request JSON from OpenAI\n",
    "        chat_params[\"response_format\"] = {\"type\": \"json_object\"}\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(**chat_params)\n",
    "        answer = response.choices[0].message.content\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        log.error(f\"Error in LLM chat: {e}\")\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "def get_plan(ques_info) -> Dict[str, Any]:\n",
    "    plan = ques_info[\"planning_agent\"]\n",
    "    plan = plan['sub_question']['final_response']\n",
    "    return plan\n",
    "\n",
    "def collect_entities_retrieved(ques_info) -> Dict[str, Set[str]]:\n",
    "    entities_retrieved = {}\n",
    "    agent = ques_info[\"sparql_executor_agent\"]\n",
    "    \n",
    "    for step in agent.keys():\n",
    "        if \"step\" not in step:\n",
    "            continue\n",
    "        \n",
    "        step_info = agent[step]\n",
    "        \n",
    "        if isinstance(step_info[\"_results\"], str):\n",
    "            entities_retrieved[step] = set()\n",
    "            continue\n",
    "        \n",
    "        if \"linked_entities\" in step_info[\"_results\"]:\n",
    "            entities_retrieved[step] = set(step_info[\"_results\"][\"linked_entities\"])\n",
    "            \n",
    "        elif \"important_entities\" in step_info[\"_results\"]:\n",
    "            entities_retrieved[step] = set(step_info[\"_results\"][\"important_entities\"])\n",
    "            \n",
    "        else:\n",
    "            for _rk,_rv in step_info[\"_results\"].items():\n",
    "                entities_retrieved[step] = set([_rk])\n",
    "                for _ve in _rv:\n",
    "                    if \"o\" in _ve:\n",
    "                        entities_retrieved[step].add(_ve[\"o\"])\n",
    "                    else:\n",
    "                        entities_retrieved[step].add(_ve[\"po\"])\n",
    "                                           \n",
    "    return entities_retrieved\n",
    "\n",
    "def get_gt_info(gt_item) -> Dict[str, Any]:\n",
    "    answer = gt_item[\"answer\"]\n",
    "    results = gt_item[\"results\"]\n",
    "    entity = gt_item[\"entity\"]\n",
    "    \n",
    "    ANS_TEMPLATE = f\"\"\"\n",
    "    {answer}\n",
    "    \n",
    "    The results obtained are: \n",
    "    {results}\n",
    "    \n",
    "    Entities involved are:\n",
    "    {entity}\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\"entity\": entity, \"answer\": ANS_TEMPLATE}\n",
    "\n",
    "def llm_evaluation(llm_answer, gt_answer) -> Dict[str, float]:\n",
    "    system_prompt = \"\"\"\n",
    "    You are an evaluation agent that compares the output of a language model against a ground truth answer. \n",
    "    Your task is to assess the quality of the language model's answer.\n",
    "    \n",
    "    Output Format:\n",
    "    Provide your evaluation in the following JSON format:\n",
    "    {\n",
    "        \"completeness\": <score from 1 to 5>,\n",
    "        \"accuracy\": <score from 1 to 5>,\n",
    "        \"relevance\": <score from 1 to 5>\n",
    "    }\n",
    "    \n",
    "    Guidelines for Evaluation:\n",
    "    1. Completeness: Check if the LLM's answer covers all aspects of the ground truth answer.\n",
    "    2. Accuracy: Verify that the information provided in the LLM's answer is correct and aligns with the ground truth.\n",
    "    3. Relevance: Ensure that the LLM's answer is pertinent to the question asked and does not include extraneous information.\n",
    "    \n",
    "    Scoring:\n",
    "     - give a score from 0 to 1 for each of the following metrics: completeness, accuracy, relevance.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "    Ground Truth Answer:\n",
    "    \n",
    "    {gt_answer}\n",
    "    \n",
    "    LLM Answer:\n",
    "    \n",
    "    {llm_answer}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm_chat(system_prompt, user_prompt, \"gpt-4o\")\n",
    "    response = return_json_formatted(response)\n",
    "    return response\n",
    "\n",
    "def prec_recall(llm_answer, gt_answer) -> Dict[str, float]:\n",
    "    max_step = list(map(lambda x: int(x.replace(\"step\", \"\")), llm_answer.keys()))\n",
    "    final_step_ent = llm_answer[f\"step{max(max_step)}\"]\n",
    "    total_retrived_entities = [x for y in llm_answer.values() for x in y]\n",
    "    gt_ent = set(gt_answer[\"entity\"])\n",
    "    \n",
    "    print(f\"GT Entities: {gt_ent}\")\n",
    "    print(f\"Final Step Entities: {set(final_step_ent)}\")\n",
    "    print(f\"Total Retrieved Entities: {set(total_retrived_entities)}\")\n",
    "    \n",
    "    true_positives_final = len(set(final_step_ent) & gt_ent)\n",
    "    false_negatives = len(gt_ent - set(final_step_ent))\n",
    "    recall_final = true_positives_final / (true_positives_final + false_negatives) if (true_positives_final + false_negatives) > 0 else 0.0\n",
    "    \n",
    "    true_positive_all = len(set(total_retrived_entities) & gt_ent)\n",
    "    false_negatives_all = len(gt_ent - set(total_retrived_entities))\n",
    "    recall_total = true_positive_all / (true_positive_all + false_negatives_all) if (true_positive_all + false_negatives_all) > 0 else 0.0\n",
    "    \n",
    "    return {\"recall_final\": recall_final, \"recall_total\": recall_total, \"total_retrived_entities\": len(total_retrived_entities)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4eb15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:39 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: {'http://testwebsite/testProgram#AI_Task-information_extractor-Input-text'}\n",
      "Final Step Entities: {\"Extract all the main ingredients without any subsidiary; return in singular noun form and First letter capital. Extract mean and dairy product in its' base form. (e.g., from 'egg white' extract 'Egg')@en^^<xsd:string>\", 'http://testwebsite/testProgram#AI_Task-information_extractor-Input-text'}\n",
      "Total Retrieved Entities: {'http://testwebsite/testProgram#AI_Task-Pipeline', \"Extract all the main ingredients without any subsidiary; return in singular noun form and First letter capital. Extract mean and dairy product in its' base form. (e.g., from 'egg white' extract 'Egg')@en^^<xsd:string>\", 'http://testwebsite/testProgram#AI_Task-llm_chat', 'http://testwebsite/testProgram#AI_Task-information_extractor-Input-text', 'http://testwebsite/testProgram#AI_Task-information_extractor-Input-builder_llm', 'http://testwebsite/testProgram#AI_Task-system_prompt_generator', 'http://testwebsite/testProgram#AI_Task-batch_sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-information_extractor', 'http://testwebsite/testProgram#AI_Task-sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-query_result_post_processor', 'http://testwebsite/testProgram#AI_Task-DF_combine'}\n",
      "{'completeness': 0.8, 'accuracy': 0.9, 'relevance': 0.7}\n",
      "{'recall_final': 1.0, 'recall_total': 1.0, 'total_retrived_entities': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:40 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: {'http://testwebsite/testProgram#AI_Task-system_prompt_generator-Input-builder_llm'}\n",
      "Final Step Entities: {'gpt-4o@en^^<xsd:string>', 'http://testwebsite/testProgram#AI_Task-system_prompt_generator-Input-builder_llm'}\n",
      "Total Retrieved Entities: {'gpt-4o@en^^<xsd:string>', 'http://testwebsite/testProgram#AI_Task-Pipeline', 'http://testwebsite/testProgram#AI_Task-llm_chat', 'http://testwebsite/testProgram#AI_Task-system_prompt_generator', 'http://testwebsite/testProgram#AI_Task-batch_sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-information_extractor', 'http://testwebsite/testProgram#AI_Task-sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-query_result_post_processor', 'http://testwebsite/testProgram#AI_Task-DF_combine', 'http://testwebsite/testProgram#AI_Task-system_prompt_generator-Input-builder_llm'}\n",
      "{'completeness': 0.5, 'accuracy': 0.5, 'relevance': 0.3}\n",
      "{'recall_final': 1.0, 'recall_total': 1.0, 'total_retrived_entities': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:42 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: {'http://testwebsite/testProgram#Data-id_20251125040052_369-kg_info', 'http://testwebsite/testProgram#Data-id_20251125040052_494-kg_info', 'http://testwebsite/testProgram#Data-id_20251125040053_856-kg_info', 'http://testwebsite/testProgram#Data-id_20251125040053_606-kg_info', 'http://testwebsite/testProgram#Data-id_20251125040053_718-kg_info', 'http://testwebsite/testProgram#Data-id_20251125040053_793-kg_info', 'http://testwebsite/testProgram#Data-id_20251125040053_493-kg_info', 'http://testwebsite/testProgram#Data-id_20251125040053_508-kg_info', 'http://testwebsite/testProgram#Data-id_20251125040053_594-kg_info', 'http://testwebsite/testProgram#Data-id_20251125040053_455-kg_info', 'http://testwebsite/testProgram#Data-id_20251125040053_188-kg_info'}\n",
      "Final Step Entities: {'@en^^<xsd:string>', 'http://testwebsite/testProgram#Collection-id_20251125040052_388-kg_info', 'NA@en^^<xsd:string>', 'http://purl.org/provone#Data'}\n",
      "Total Retrieved Entities: {'http://testwebsite/testProgram#Collection-id_20251125040053_806-kg_info', 'http://testwebsite/testProgram#id_20251125040050_988', 'http://testwebsite/testProgram#id_20251125040037_323', 'http://testwebsite/testProgram#id_20251125040053_581', 'http://testwebsite/testProgram#Collection-id_20251125040053_821-kg_info', 'http://testwebsite/testProgram#id_20251125040053_684', 'NA@en^^<xsd:string>', 'http://testwebsite/testProgram#Collection-id_20251125040053_380-kg_info', 'http://testwebsite/testProgram#Collection-id_20251125040053_57-kg_info', 'http://testwebsite/testProgram#id_20251125040053_658', 'http://testwebsite/testProgram#Collection-id_20251125040053_338-kg_info', 'http://testwebsite/testProgram#id_20251125040053_688', 'http://testwebsite/testProgram#id_20251125040052_790', 'http://testwebsite/testProgram#Collection-id_20251125040053_501-kg_info', 'http://testwebsite/testProgram#id_20251125040053_82', 'http://testwebsite/testProgram#id_20251125040053_179', 'http://purl.org/provone#Data', 'http://testwebsite/testProgram#Collection-id_20251125040052_388-kg_info', 'http://testwebsite/testProgram#Collection-id_20251125040053_251-kg_info', '@en^^<xsd:string>', 'http://testwebsite/testProgram#id_20251125040053_85', 'http://testwebsite/testProgram#id_20251125040053_196', 'http://testwebsite/testProgram#id_20251125040052_65'}\n",
      "{'completeness': 0.5, 'accuracy': 0.5, 'relevance': 0.5}\n",
      "{'recall_final': 0.0, 'recall_total': 0.0, 'total_retrived_entities': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:43 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: {'http://testwebsite/testProgram#AI_Task-information_extractor-Input-builder_llm'}\n",
      "Final Step Entities: {'http://testwebsite/testProgram#AI_Task-information_extractor-Input-builder_llm', 'gpt-4o@en^^<xsd:string>'}\n",
      "Total Retrieved Entities: {'gpt-4o@en^^<xsd:string>', 'http://testwebsite/testProgram#AI_Task-Pipeline', 'http://testwebsite/testProgram#AI_Task-llm_chat', 'http://testwebsite/testProgram#AI_Task-information_extractor-Input-builder_llm', 'http://testwebsite/testProgram#AI_Task-system_prompt_generator', 'http://testwebsite/testProgram#AI_Task-batch_sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-information_extractor', 'http://testwebsite/testProgram#AI_Task-sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-query_result_post_processor', 'http://testwebsite/testProgram#AI_Task-DF_combine'}\n",
      "{'completeness': 1, 'accuracy': 1, 'relevance': 1}\n",
      "{'recall_final': 1.0, 'recall_total': 1.0, 'total_retrived_entities': 11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:43 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: {'http://testwebsite/testProgram#AI_Task-query_result_post_processor-Input-formatting_instruction', 'http://testwebsite/testProgram#AI_Task-query_result_post_processor-Input-processing_instruction'}\n",
      "Final Step Entities: {\"If there are duplicate ingredients then select row with most information on `sugarG` and `ingredientCat` columns. Fill all the missing values with '0' in `sugarG` column and with '-' in 'ingredientCat` column.@en^^<xsd:string>\", 'http://testwebsite/testProgram#AI_Task-query_result_post_processor-Input-processing_instruction'}\n",
      "Total Retrieved Entities: {\"If there are duplicate ingredients then select row with most information on `sugarG` and `ingredientCat` columns. Fill all the missing values with '0' in `sugarG` column and with '-' in 'ingredientCat` column.@en^^<xsd:string>\", 'http://testwebsite/testProgram#AI_Task-Pipeline', 'http://testwebsite/testProgram#AI_Task-llm_chat', 'http://testwebsite/testProgram#AI_Task-query_result_post_processor-Input-processing_instruction', 'http://testwebsite/testProgram#AI_Task-system_prompt_generator', 'http://testwebsite/testProgram#AI_Task-batch_sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-information_extractor', 'http://testwebsite/testProgram#AI_Task-query_result_post_processor-Input-formatting_instruction', 'http://testwebsite/testProgram#AI_Task-sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-query_result_post_processor', 'http://testwebsite/testProgram#AI_Task-DF_combine'}\n",
      "{'completeness': 1, 'accuracy': 1, 'relevance': 1}\n",
      "{'recall_final': 0.5, 'recall_total': 1.0, 'total_retrived_entities': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:45 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "12/01/2025 10:30:45 - WARNING - __main__ -   Error parsing JSON (layer 1): Expecting value: line 1 column 1 (char 0). Trying to extract from markdown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: {'http://testwebsite/testProgram#llm_chat'}\n",
      "Final Step Entities: set()\n",
      "Total Retrieved Entities: set()\n",
      "{'completeness': 1, 'accuracy': 1, 'relevance': 1}\n",
      "{'recall_final': 0.0, 'recall_total': 0.0, 'total_retrived_entities': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:46 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: {'http://testwebsite/testProgram#AI_Task-Pipeline', 'http://testwebsite/testProgram#AI_Task-llm_chat', 'http://testwebsite/testProgram#AI_Task-system_prompt_generator', 'http://testwebsite/testProgram#AI_Task-batch_sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-information_extractor', 'http://testwebsite/testProgram#AI_Task-sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-query_result_post_processor', 'http://testwebsite/testProgram#AI_Task-DF_combine'}\n",
      "Final Step Entities: {'http://testwebsite/testProgram#AI_Task-system_prompt_generator-Input-base_sys_prompt', 'http://testwebsite/testProgram#system_prompt_generator', 'https://purl.org/heals/eo#AITask', 'http://testwebsite/testProgram#AI_Task-system_prompt_generator', 'http://testwebsite/testProgram#AI_Task-system_prompt_generator-Input-builder_llm'}\n",
      "Total Retrieved Entities: {'http://testwebsite/testProgram#AI_Task-system_prompt_generator-Input-base_sys_prompt', 'http://testwebsite/testProgram#AI_Task-batch_sparql_query_extractor', 'http://testwebsite/testProgram#Pipeline', 'http://testwebsite/testProgram#AI_Task-sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-query_result_post_processor', 'http://testwebsite/testProgram#system_prompt_generator', 'http://testwebsite/testProgram#sparql_query_extractor', 'http://testwebsite/testProgram#llm_chat', 'http://testwebsite/testProgram#batch_sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-system_prompt_generator-Input-builder_llm', 'https://purl.org/heals/eo#AITask', 'http://testwebsite/testProgram#query_result_post_processor', 'http://testwebsite/testProgram#AI_Task-Pipeline', 'http://testwebsite/testProgram#AI_Task-llm_chat', 'http://testwebsite/testProgram#AI_Task-system_prompt_generator', 'http://testwebsite/testProgram#information_extractor', 'http://testwebsite/testProgram#AI_Task-information_extractor', 'http://testwebsite/testProgram#DF_combine', 'http://testwebsite/testProgram#AI_Task-DF_combine'}\n",
      "{'completeness': 0.5, 'accuracy': 0.5, 'relevance': 0.5}\n",
      "{'recall_final': 0.125, 'recall_total': 1.0, 'total_retrived_entities': 21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:48 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: {'http://testwebsite/testProgram#Data-id_20251125040052_801-extracts', 'http://testwebsite/testProgram#Data-id_20251125040052_440-extracts', 'http://testwebsite/testProgram#Data-id_20251125040052_762-extracts', 'http://testwebsite/testProgram#Data-id_20251125040052_146-extracts', 'http://testwebsite/testProgram#Data-id_20251125040052_740-extracts', 'http://testwebsite/testProgram#Data-id_20251125040052_802-extracts', 'http://testwebsite/testProgram#Data-id_20251125040052_631-extracts', 'http://testwebsite/testProgram#Data-id_20251125040052_394-extracts'}\n",
      "Final Step Entities: {'Pepper@en^^<xsd:string>', 'http://purl.org/provone#Data', 'Feta cheese@en^^<xsd:string>', 'Egg@en^^<xsd:string>', 'Salt@en^^<xsd:string>', 'Spinach@en^^<xsd:string>', 'http://testwebsite/testProgram#Collection-id_20251125040052_285-extracts', 'Turkey bacon@en^^<xsd:string>', 'Parsley@en^^<xsd:string>', 'Olive oil@en^^<xsd:string>'}\n",
      "Total Retrieved Entities: {'http://testwebsite/testProgram#Collection-id_20251125040053_806-kg_info', 'http://testwebsite/testProgram#Collection-id_20251125040053_300-post_processed_output', 'http://testwebsite/testProgram#id_20251125040050_988', 'http://testwebsite/testProgram#id_20251125040037_323', 'http://testwebsite/testProgram#id_20251125040053_581', 'http://testwebsite/testProgram#Collection-id_20251125040053_821-kg_info', 'http://testwebsite/testProgram#id_20251125040053_684', 'http://testwebsite/testProgram#Collection-id_20251125040052_285-extracts', 'Feta cheese@en^^<xsd:string>', 'http://testwebsite/testProgram#Collection-id_20251125040053_380-kg_info', 'http://testwebsite/testProgram#Collection-id_20251125040053_57-kg_info', 'Pepper@en^^<xsd:string>', 'http://testwebsite/testProgram#id_20251125040053_658', 'http://testwebsite/testProgram#Collection-id_20251125040053_338-kg_info', 'http://testwebsite/testProgram#id_20251125040053_688', 'Spinach@en^^<xsd:string>', 'http://testwebsite/testProgram#id_20251125040052_790', 'Turkey bacon@en^^<xsd:string>', 'http://testwebsite/testProgram#Collection-id_20251125040053_501-kg_info', 'http://testwebsite/testProgram#id_20251125040053_82', 'http://testwebsite/testProgram#id_20251125040053_179', 'Olive oil@en^^<xsd:string>', 'http://purl.org/provone#Data', 'http://testwebsite/testProgram#Collection-id_20251125040052_388-kg_info', 'http://testwebsite/testProgram#Collection-id_20251125040053_251-kg_info', 'Parsley@en^^<xsd:string>', 'http://testwebsite/testProgram#id_20251125040053_85', 'http://testwebsite/testProgram#id_20251125040053_196', 'Egg@en^^<xsd:string>', 'http://testwebsite/testProgram#id_20251125040052_65', 'Salt@en^^<xsd:string>'}\n",
      "{'completeness': 0.9, 'accuracy': 0.9, 'relevance': 1.0}\n",
      "{'recall_final': 0.0, 'recall_total': 0.0, 'total_retrived_entities': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:50 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "12/01/2025 10:30:50 - WARNING - __main__ -   Error parsing JSON (layer 1): Expecting value: line 1 column 1 (char 0). Trying to extract from markdown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: set()\n",
      "Final Step Entities: {'http://testwebsite/testProgram#AI_Task-sparql_query_extractor-Input-sparql_query_template', 'PREFIX dbo: <http://dbpedia.org/ontology/>\\nPREFIX dbp: <http://dbpedia.org/property/>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nPREFIX dcterms: <http://purl.org/dc/terms/>\\nPREFIX dbt: <http://dbpedia.org/resource/Template:>\\nPREFIX skos: <http://www.w3.org/2004/02/skos/core#>\\n\\nSELECT (STR(?ingredientLabel) AS ?ingredientName) \\n       (STR(?sugar) AS ?sugarG) \\n       (STR(?subjectLabel) AS ?ingredientCat) \\nWHERE {\\n  ?ingredient rdfs:label ?ingredientLabel .\\n  FILTER (?ingredientLabel = \"%s\"@en) .\\n\\n  OPTIONAL { ?ingredient dbp:sugars ?sugar . }\\n\\n  ?ingredient dcterms:subject ?subject .\\n  OPTIONAL { ?subject rdfs:label ?subjectLabel . }\\n\\n  ?subject dbp:wikiPageUsesTemplate ?template0 .\\n  FILTER (?template0 IN (dbt:CatAutoTOC, dbt:Cookbook))\\n  ?subject skos:broader ?broader .\\n\\n  OPTIONAL {\\n    ?broader dbp:wikiPageUsesTemplate ?template .\\n    BIND(IF(?template = dbt:CatAutoTOC, 1, 0) AS ?autoCount)\\n    BIND(IF(?template = dbt:Cookbook, 1, 0) AS ?cookCount)\\n  }\\n}\\nGROUP BY ?ingredient ?ingredientLabel ?sugar ?subjectLabel\\nORDER BY DESC(?BroaderCount)\\nLIMIT 1@en^^<xsd:string>'}\n",
      "Total Retrieved Entities: {'http://testwebsite/testProgram#AI_Task-sparql_query_extractor-Input-sparql_query_template', 'http://testwebsite/testProgram#AI_Task-Pipeline', 'http://testwebsite/testProgram#AI_Task-llm_chat', 'http://testwebsite/testProgram#AI_Task-system_prompt_generator', 'http://testwebsite/testProgram#AI_Task-sparql_query_extractor-Input-endpoint', 'http://testwebsite/testProgram#AI_Task-batch_sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-information_extractor', 'PREFIX dbo: <http://dbpedia.org/ontology/>\\nPREFIX dbp: <http://dbpedia.org/property/>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nPREFIX dcterms: <http://purl.org/dc/terms/>\\nPREFIX dbt: <http://dbpedia.org/resource/Template:>\\nPREFIX skos: <http://www.w3.org/2004/02/skos/core#>\\n\\nSELECT (STR(?ingredientLabel) AS ?ingredientName) \\n       (STR(?sugar) AS ?sugarG) \\n       (STR(?subjectLabel) AS ?ingredientCat) \\nWHERE {\\n  ?ingredient rdfs:label ?ingredientLabel .\\n  FILTER (?ingredientLabel = \"%s\"@en) .\\n\\n  OPTIONAL { ?ingredient dbp:sugars ?sugar . }\\n\\n  ?ingredient dcterms:subject ?subject .\\n  OPTIONAL { ?subject rdfs:label ?subjectLabel . }\\n\\n  ?subject dbp:wikiPageUsesTemplate ?template0 .\\n  FILTER (?template0 IN (dbt:CatAutoTOC, dbt:Cookbook))\\n  ?subject skos:broader ?broader .\\n\\n  OPTIONAL {\\n    ?broader dbp:wikiPageUsesTemplate ?template .\\n    BIND(IF(?template = dbt:CatAutoTOC, 1, 0) AS ?autoCount)\\n    BIND(IF(?template = dbt:Cookbook, 1, 0) AS ?cookCount)\\n  }\\n}\\nGROUP BY ?ingredient ?ingredientLabel ?sugar ?subjectLabel\\nORDER BY DESC(?BroaderCount)\\nLIMIT 1@en^^<xsd:string>', 'http://testwebsite/testProgram#AI_Task-sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-query_result_post_processor', 'http://testwebsite/testProgram#AI_Task-DF_combine'}\n",
      "{'completeness': 0.5, 'accuracy': 0.5, 'relevance': 0.5}\n",
      "{'recall_final': 0.0, 'recall_total': 0.0, 'total_retrived_entities': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:51 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "12/01/2025 10:30:51 - WARNING - __main__ -   Error parsing JSON (layer 1): Expecting value: line 1 column 1 (char 0). Trying to extract from markdown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: {'http://testwebsite/testProgram#Data-id_20251125040037_520-system_prompt'}\n",
      "Final Step Entities: {'http://testwebsite/testProgram#id_20251125040037_323', \"You are a culinary assistant that recommends one personalized dish per request, complete with ingredients and step-by-step instructions. Focus on dietary needs, allergy safety, and easy, enjoyable cooking. You will consider the user's details: 30, Male, diagnosis: Diabetic, height: 182.3, weight: 95.2, BMI: 28.6, food preferences: Carnivore, and allergies: None.@en^^<xsd:string>\", 'http://testwebsite/testProgram#Data-id_20251125040037_520-system_prompt', 'http://purl.org/provone#Data'}\n",
      "Total Retrieved Entities: {'http://testwebsite/testProgram#id_20251125040053_658', 'http://testwebsite/testProgram#id_20251125040053_85', 'http://purl.org/provone#Data', 'http://testwebsite/testProgram#id_20251125040037_323', 'http://testwebsite/testProgram#id_20251125040050_988', 'http://testwebsite/testProgram#id_20251125040053_196', 'http://testwebsite/testProgram#id_20251125040053_581', 'http://testwebsite/testProgram#id_20251125040053_688', 'http://testwebsite/testProgram#Data-id_20251125040037_520-system_prompt', 'http://testwebsite/testProgram#id_20251125040053_684', 'http://testwebsite/testProgram#id_20251125040052_790', \"You are a culinary assistant that recommends one personalized dish per request, complete with ingredients and step-by-step instructions. Focus on dietary needs, allergy safety, and easy, enjoyable cooking. You will consider the user's details: 30, Male, diagnosis: Diabetic, height: 182.3, weight: 95.2, BMI: 28.6, food preferences: Carnivore, and allergies: None.@en^^<xsd:string>\", 'http://testwebsite/testProgram#id_20251125040052_65', 'http://testwebsite/testProgram#id_20251125040053_82', 'http://testwebsite/testProgram#id_20251125040053_179'}\n",
      "{'completeness': 0.9, 'accuracy': 0.9, 'relevance': 1.0}\n",
      "{'recall_final': 1.0, 'recall_total': 1.0, 'total_retrived_entities': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:52 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: {'http://testwebsite/testProgram#system_prompt_generator', 'Batch SPARQL Query Extractor@en^^<xsd:string>', 'SPARQL Query Builder@en^^<xsd:string>', 'http://testwebsite/testProgram#query_result_post_processor', 'Query Result Post-Processor@en^^<xsd:string>', 'http://testwebsite/testProgram#information_extractor', 'http://testwebsite/testProgram#sparql_query_extractor', 'Information Extractor@en^^<xsd:string>', 'http://testwebsite/testProgram#DF_combine', 'System Prompt Template Generator@en^^<xsd:string>', 'Data Frame Combiner@en^^<xsd:string>', 'http://testwebsite/testProgram#batch_sparql_query_extractor'}\n",
      "Final Step Entities: {'https://purl.org/heals/eo#SystemRecommendation', 'http://testwebsite/testProgram#sparql_query_extractor-entity', 'SPARQL Query Builder@en^^<xsd:string>', '3@en^^<xsd:string>', 'http://testwebsite/testProgram#sparql_query_extractor', '2025-11-09 19:30:53@en^^<xsd:string>', 'Builds SPARQL queries to extract information about the entities from the knowledge graph.@en^^<xsd:string>', 'http://purl.org/provone#Program', 'http://testwebsite/testProgram#AI_Task-sparql_query_extractor', 'http://testwebsite/testProgram#sparql_query_extractor-kg_info'}\n",
      "Total Retrieved Entities: {'https://purl.org/heals/eo#SystemRecommendation', 'http://testwebsite/testProgram#system_prompt_generator', 'http://testwebsite/testProgram#sparql_query_extractor-entity', 'SPARQL Query Builder@en^^<xsd:string>', 'http://testwebsite/testProgram#query_result_post_processor', '3@en^^<xsd:string>', 'http://testwebsite/testProgram#information_extractor', 'http://testwebsite/testProgram#Pipeline', 'http://testwebsite/testProgram#sparql_query_extractor', '2025-11-09 19:30:53@en^^<xsd:string>', 'Builds SPARQL queries to extract information about the entities from the knowledge graph.@en^^<xsd:string>', 'http://testwebsite/testProgram#DF_combine', 'http://testwebsite/testProgram#llm_chat', 'http://purl.org/provone#Program', 'http://testwebsite/testProgram#AI_Task-sparql_query_extractor', 'http://testwebsite/testProgram#sparql_query_extractor-kg_info', 'http://testwebsite/testProgram#batch_sparql_query_extractor'}\n",
      "{'completeness': 0.5, 'accuracy': 0.5, 'relevance': 0.5}\n",
      "{'recall_final': 0.16666666666666666, 'recall_total': 0.5833333333333334, 'total_retrived_entities': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:53 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: {'http://testwebsite/testProgram#information_extractor'}\n",
      "Final Step Entities: set()\n",
      "Total Retrieved Entities: set()\n",
      "{'completeness': 0, 'accuracy': 0, 'relevance': 0}\n",
      "{'recall_final': 0.0, 'recall_total': 0.0, 'total_retrived_entities': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/01/2025 10:30:54 - INFO - httpx -   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "12/01/2025 10:30:54 - WARNING - __main__ -   Error parsing JSON (layer 1): Expecting value: line 1 column 1 (char 0). Trying to extract from markdown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Entities: {'http://testwebsite/testProgram#AI_Task-sparql_query_extractor-Input-sparql_query_template'}\n",
      "Final Step Entities: {'http://testwebsite/testProgram#AI_Task-sparql_query_extractor-Input-sparql_query_template', 'PREFIX dbo: <http://dbpedia.org/ontology/>\\nPREFIX dbp: <http://dbpedia.org/property/>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nPREFIX dcterms: <http://purl.org/dc/terms/>\\nPREFIX dbt: <http://dbpedia.org/resource/Template:>\\nPREFIX skos: <http://www.w3.org/2004/02/skos/core#>\\n\\nSELECT (STR(?ingredientLabel) AS ?ingredientName) \\n       (STR(?sugar) AS ?sugarG) \\n       (STR(?subjectLabel) AS ?ingredientCat) \\nWHERE {\\n  ?ingredient rdfs:label ?ingredientLabel .\\n  FILTER (?ingredientLabel = \"%s\"@en) .\\n\\n  OPTIONAL { ?ingredient dbp:sugars ?sugar . }\\n\\n  ?ingredient dcterms:subject ?subject .\\n  OPTIONAL { ?subject rdfs:label ?subjectLabel . }\\n\\n  ?subject dbp:wikiPageUsesTemplate ?template0 .\\n  FILTER (?template0 IN (dbt:CatAutoTOC, dbt:Cookbook))\\n  ?subject skos:broader ?broader .\\n\\n  OPTIONAL {\\n    ?broader dbp:wikiPageUsesTemplate ?template .\\n    BIND(IF(?template = dbt:CatAutoTOC, 1, 0) AS ?autoCount)\\n    BIND(IF(?template = dbt:Cookbook, 1, 0) AS ?cookCount)\\n  }\\n}\\nGROUP BY ?ingredient ?ingredientLabel ?sugar ?subjectLabel\\nORDER BY DESC(?BroaderCount)\\nLIMIT 1@en^^<xsd:string>'}\n",
      "Total Retrieved Entities: {'http://testwebsite/testProgram#AI_Task-sparql_query_extractor-Input-sparql_query_template', 'http://testwebsite/testProgram#AI_Task-Pipeline', 'http://testwebsite/testProgram#AI_Task-llm_chat', 'http://testwebsite/testProgram#AI_Task-system_prompt_generator', 'http://testwebsite/testProgram#AI_Task-sparql_query_extractor-Input-endpoint', 'http://testwebsite/testProgram#AI_Task-batch_sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-information_extractor', 'PREFIX dbo: <http://dbpedia.org/ontology/>\\nPREFIX dbp: <http://dbpedia.org/property/>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nPREFIX dcterms: <http://purl.org/dc/terms/>\\nPREFIX dbt: <http://dbpedia.org/resource/Template:>\\nPREFIX skos: <http://www.w3.org/2004/02/skos/core#>\\n\\nSELECT (STR(?ingredientLabel) AS ?ingredientName) \\n       (STR(?sugar) AS ?sugarG) \\n       (STR(?subjectLabel) AS ?ingredientCat) \\nWHERE {\\n  ?ingredient rdfs:label ?ingredientLabel .\\n  FILTER (?ingredientLabel = \"%s\"@en) .\\n\\n  OPTIONAL { ?ingredient dbp:sugars ?sugar . }\\n\\n  ?ingredient dcterms:subject ?subject .\\n  OPTIONAL { ?subject rdfs:label ?subjectLabel . }\\n\\n  ?subject dbp:wikiPageUsesTemplate ?template0 .\\n  FILTER (?template0 IN (dbt:CatAutoTOC, dbt:Cookbook))\\n  ?subject skos:broader ?broader .\\n\\n  OPTIONAL {\\n    ?broader dbp:wikiPageUsesTemplate ?template .\\n    BIND(IF(?template = dbt:CatAutoTOC, 1, 0) AS ?autoCount)\\n    BIND(IF(?template = dbt:Cookbook, 1, 0) AS ?cookCount)\\n  }\\n}\\nGROUP BY ?ingredient ?ingredientLabel ?sugar ?subjectLabel\\nORDER BY DESC(?BroaderCount)\\nLIMIT 1@en^^<xsd:string>', 'http://testwebsite/testProgram#AI_Task-sparql_query_extractor', 'http://testwebsite/testProgram#AI_Task-query_result_post_processor', 'http://testwebsite/testProgram#AI_Task-DF_combine'}\n",
      "{'completeness': 0.9, 'accuracy': 0.9, 'relevance': 0.8}\n",
      "{'recall_final': 1.0, 'recall_total': 1.0, 'total_retrived_entities': 12}\n"
     ]
    }
   ],
   "source": [
    "full_res = []\n",
    "for k,v in run_info.items():\n",
    "    # if not \"what is the program that takes the system prompt created by the program system_prompt_generator as an input ?\" == k:\n",
    "    #     continue\n",
    "    #print(k)\n",
    "    #print(v[\"final_answer\"])\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    plan_ext = get_plan(v)\n",
    "    collected_entities = collect_entities_retrieved(v)\n",
    "    \n",
    "    gt_info = get_gt_info(gt[k])\n",
    "    #print(gt_info[\"entity\"])\n",
    "    #print(collected_entities)\n",
    "    \n",
    "    results[\"question\"] = v[\"question\"]\n",
    "    results[\"tags\"] = gt[k].get(\"tags\", [])\n",
    "    llm_eval = llm_evaluation(v[\"final_answer\"], gt_info[\"answer\"])\n",
    "    stats_eval = prec_recall(collected_entities, gt_info)\n",
    "    \n",
    "    print(llm_eval)\n",
    "    print(stats_eval)\n",
    "    \n",
    "    results.update(llm_eval)\n",
    "    results.update(stats_eval)\n",
    "    \n",
    "    full_res.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26164827",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_res_df = pd.DataFrame(full_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b668501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>tags</th>\n",
       "      <th>completeness</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>relevance</th>\n",
       "      <th>recall_final</th>\n",
       "      <th>recall_total</th>\n",
       "      <th>total_retrived_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what are the instructions used as an object re...</td>\n",
       "      <td>[structural]</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what was the builder llm used as an object rec...</td>\n",
       "      <td>[structural]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what was the sparql results generated by the e...</td>\n",
       "      <td>[row-level]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what was the builder llm used as an object rec...</td>\n",
       "      <td>[structural]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are the instructions used as an object re...</td>\n",
       "      <td>[structural]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>what is the program that takes the system prom...</td>\n",
       "      <td>[structural]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are the AI Tasks that generated programs?</td>\n",
       "      <td>[structural]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what were the extracted ingredients generated ...</td>\n",
       "      <td>[row-level]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what was the builder llm used as an object rec...</td>\n",
       "      <td>[structural]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what was the system prompt generated by the ex...</td>\n",
       "      <td>[row-level]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>what is the steps in order of programs?</td>\n",
       "      <td>[structural]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>what is the program that uses as input the out...</td>\n",
       "      <td>[structural]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>what was the SPARQL query used as an object re...</td>\n",
       "      <td>[row-level]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question          tags  \\\n",
       "0   what are the instructions used as an object re...  [structural]   \n",
       "1   what was the builder llm used as an object rec...  [structural]   \n",
       "2   what was the sparql results generated by the e...   [row-level]   \n",
       "3   what was the builder llm used as an object rec...  [structural]   \n",
       "4   what are the instructions used as an object re...  [structural]   \n",
       "5   what is the program that takes the system prom...  [structural]   \n",
       "6      What are the AI Tasks that generated programs?  [structural]   \n",
       "7   what were the extracted ingredients generated ...   [row-level]   \n",
       "8   what was the builder llm used as an object rec...  [structural]   \n",
       "9   what was the system prompt generated by the ex...   [row-level]   \n",
       "10            what is the steps in order of programs?  [structural]   \n",
       "11  what is the program that uses as input the out...  [structural]   \n",
       "12  what was the SPARQL query used as an object re...   [row-level]   \n",
       "\n",
       "    completeness  accuracy  relevance  recall_final  recall_total  \\\n",
       "0            0.8       0.9        0.7      1.000000      1.000000   \n",
       "1            0.5       0.5        0.3      1.000000      1.000000   \n",
       "2            0.5       0.5        0.5      0.000000      0.000000   \n",
       "3            1.0       1.0        1.0      1.000000      1.000000   \n",
       "4            1.0       1.0        1.0      0.500000      1.000000   \n",
       "5            1.0       1.0        1.0      0.000000      0.000000   \n",
       "6            0.5       0.5        0.5      0.125000      1.000000   \n",
       "7            0.9       0.9        1.0      0.000000      0.000000   \n",
       "8            0.5       0.5        0.5      0.000000      0.000000   \n",
       "9            0.9       0.9        1.0      1.000000      1.000000   \n",
       "10           0.5       0.5        0.5      0.166667      0.583333   \n",
       "11           0.0       0.0        0.0      0.000000      0.000000   \n",
       "12           0.9       0.9        0.8      1.000000      1.000000   \n",
       "\n",
       "    total_retrived_entities  \n",
       "0                        12  \n",
       "1                        12  \n",
       "2                        32  \n",
       "3                        11  \n",
       "4                        12  \n",
       "5                         0  \n",
       "6                        21  \n",
       "7                        32  \n",
       "8                        12  \n",
       "9                        18  \n",
       "10                       18  \n",
       "11                        0  \n",
       "12                       12  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be732d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "completeness    0.762500\n",
       "accuracy        0.775000\n",
       "relevance       0.725000\n",
       "recall_final    0.723958\n",
       "recall_total    0.947917\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_res_df.loc[(full_res_df[\"recall_final\"] > 0) & (full_res_df[\"recall_total\"] > 0), [\"completeness\", \"accuracy\", \"relevance\", \"recall_final\", \"recall_total\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e80426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"evaluations\", exist_ok=True)\n",
    "full_res_df.to_csv(os.path.join(\"evaluations\", \"v3_evaluation.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "315031a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the order of execution for the specified programs in the system, we refer to the identifiers and timestamps provided for each program. Based on the attributes and available data, here's how the order of programs appears:\n",
      "\n",
      "1. **System Prompt Template Generator**: \n",
      "   - **Label**: \"System Prompt Template Generator\"\n",
      "   - **Description**: Generates a system prompt based on the user input and dataset structure.\n",
      "   - **Identifier**: 1\n",
      "   - **Timestamp**: 2025-11-09 19:29:12\n",
      "\n",
      "   This program initiates the sequence by generating prompts that will be leveraged by the subsequent components, indicating a foundational role in setting up necessary prompt structures that will guide the system behavior.\n",
      "\n",
      "2. **Information Extractor**: \n",
      "   - **Label**: \"Information Extractor\"\n",
      "   - **Description**: Extracts entities or relevant information from the generated text.\n",
      "   - **Identifier**: 2\n",
      "   - **Timestamp**: 2025-11-09 19:30:27\n",
      "\n",
      "   This program operates soon after the prompt template is generated, identifying and extracting key information based on interactions or generated text from the system.\n",
      "\n",
      "3. **Batch SPARQL Query Extractor**: \n",
      "   - **Label**: \"Batch SPARQL Query Extractor\"\n",
      "   - **Description**: Extracts knowledge from the graph in batch mode.\n",
      "   - **Identifier**: 3\n",
      "   - **Timestamp**: 2025-11-09 19:30:53\n",
      "\n",
      "   Alongside extracting data, the Batch SPARQL Query Extractor also involves in the initial processing phase, identifying key data from knowledge graphs in batches.\n",
      "\n",
      "   - **SPARQL Query Builder** is part of this phase as well:\n",
      "     - It is identified by the same identifier and performs SPARQL query building as a subtask of batch extraction.\n",
      "\n",
      "4. **Data Frame Combiner**: \n",
      "   - **Label**: \"Data Frame Combiner\"\n",
      "   - **Description**: Combines multiple data frames resulting from SPARQL queries.\n",
      "   - **Identifier**: 3\n",
      "\n",
      "   While operated simultaneously with the batch SPARQL extractor (given identical identifiers), this can also indicate that it processes after SPARQL queries have extracted the necessary data.\n",
      "\n",
      "5. **LLM Chat**: \n",
      "   - **Label**: \"LLM Chat\"\n",
      "   - **Description**: Used for communication with the language model (LLM).\n",
      "   - **Timestamp**: (not explicitly provided in the context, typically following extraction and combination phases to utilize processed data or prompt structure)\n",
      "\n",
      "6. **Query Result Post-Processor**: \n",
      "   - **Label**: \"Query Result Post-Processor\"\n",
      "   - **Description**: Finalizes the processing of the query results.\n",
      "   - **Identifier**: 4\n",
      "   - **Timestamp**: 2025-11-09 19:32:26\n",
      "\n",
      "   This program is the final component, refining the data set results into usable outputs.\n",
      "\n",
      "Collectively, this sequence constitutes a pipeline that begins with generating necessary prompts, analyzing and extracting relevant data, and then processing and refining the results before the interaction with an LLM model.\n",
      "\n",
      "### Important Facts:\n",
      "1. **Pipeline Steps**:\n",
      "   - \"System Prompt Template Generator\" initiated as step 1. - [Link](http://testwebsite/testProgram#system_prompt_generator)\n",
      "   - Subsequent processing involves \"Information Extractor\", \"Batch SPARQL Query Extractor\", and \"Data Frame Combiner\". - [Link](http://testwebsite/testProgram#information_extractor), [Link](http://testwebsite/testProgram#batch_sparql_query_extractor), [Link](http://testwebsite/testProgram#DF_combine)\n",
      "   - These are followed by \"LLM Chat\" and culminate with \"Query Result Post-Processor\". - [Link](http://testwebsite/testProgram#query_result_post_processor), [Link](http://testwebsite/testProgram#llm_chat)\n",
      "\n",
      "2. **Identifier and Timestamps**: \n",
      "   - Identifiers (1 to 4) suggest order and execution priority based on timestamps when available. - [Link](http://testwebsite/testProgram#sparql_query_extractor)\n",
      "\n",
      "Through these analyses, the organization of execution steps becomes evident, forming a coherent flow for data and information processing within the system pipeline.\n"
     ]
    }
   ],
   "source": [
    "print(\"To determine the order of execution for the specified programs in the system, we refer to the identifiers and timestamps provided for each program. Based on the attributes and available data, here's how the order of programs appears:\\n\\n1. **System Prompt Template Generator**: \\n   - **Label**: \\\"System Prompt Template Generator\\\"\\n   - **Description**: Generates a system prompt based on the user input and dataset structure.\\n   - **Identifier**: 1\\n   - **Timestamp**: 2025-11-09 19:29:12\\n\\n   This program initiates the sequence by generating prompts that will be leveraged by the subsequent components, indicating a foundational role in setting up necessary prompt structures that will guide the system behavior.\\n\\n2. **Information Extractor**: \\n   - **Label**: \\\"Information Extractor\\\"\\n   - **Description**: Extracts entities or relevant information from the generated text.\\n   - **Identifier**: 2\\n   - **Timestamp**: 2025-11-09 19:30:27\\n\\n   This program operates soon after the prompt template is generated, identifying and extracting key information based on interactions or generated text from the system.\\n\\n3. **Batch SPARQL Query Extractor**: \\n   - **Label**: \\\"Batch SPARQL Query Extractor\\\"\\n   - **Description**: Extracts knowledge from the graph in batch mode.\\n   - **Identifier**: 3\\n   - **Timestamp**: 2025-11-09 19:30:53\\n\\n   Alongside extracting data, the Batch SPARQL Query Extractor also involves in the initial processing phase, identifying key data from knowledge graphs in batches.\\n\\n   - **SPARQL Query Builder** is part of this phase as well:\\n     - It is identified by the same identifier and performs SPARQL query building as a subtask of batch extraction.\\n\\n4. **Data Frame Combiner**: \\n   - **Label**: \\\"Data Frame Combiner\\\"\\n   - **Description**: Combines multiple data frames resulting from SPARQL queries.\\n   - **Identifier**: 3\\n\\n   While operated simultaneously with the batch SPARQL extractor (given identical identifiers), this can also indicate that it processes after SPARQL queries have extracted the necessary data.\\n\\n5. **LLM Chat**: \\n   - **Label**: \\\"LLM Chat\\\"\\n   - **Description**: Used for communication with the language model (LLM).\\n   - **Timestamp**: (not explicitly provided in the context, typically following extraction and combination phases to utilize processed data or prompt structure)\\n\\n6. **Query Result Post-Processor**: \\n   - **Label**: \\\"Query Result Post-Processor\\\"\\n   - **Description**: Finalizes the processing of the query results.\\n   - **Identifier**: 4\\n   - **Timestamp**: 2025-11-09 19:32:26\\n\\n   This program is the final component, refining the data set results into usable outputs.\\n\\nCollectively, this sequence constitutes a pipeline that begins with generating necessary prompts, analyzing and extracting relevant data, and then processing and refining the results before the interaction with an LLM model.\\n\\n### Important Facts:\\n1. **Pipeline Steps**:\\n   - \\\"System Prompt Template Generator\\\" initiated as step 1. - [Link](http://testwebsite/testProgram#system_prompt_generator)\\n   - Subsequent processing involves \\\"Information Extractor\\\", \\\"Batch SPARQL Query Extractor\\\", and \\\"Data Frame Combiner\\\". - [Link](http://testwebsite/testProgram#information_extractor), [Link](http://testwebsite/testProgram#batch_sparql_query_extractor), [Link](http://testwebsite/testProgram#DF_combine)\\n   - These are followed by \\\"LLM Chat\\\" and culminate with \\\"Query Result Post-Processor\\\". - [Link](http://testwebsite/testProgram#query_result_post_processor), [Link](http://testwebsite/testProgram#llm_chat)\\n\\n2. **Identifier and Timestamps**: \\n   - Identifiers (1 to 4) suggest order and execution priority based on timestamps when available. - [Link](http://testwebsite/testProgram#sparql_query_extractor)\\n\\nThrough these analyses, the organization of execution steps becomes evident, forming a coherent flow for data and information processing within the system pipeline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d56c6a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_res_df[\"ques_type\"] = full_res_df[\"tags\"].apply(lambda x: \"row-level\" if \"row-level\" in x else \"structural\")\n",
    "full_res_df = full_res_df.drop(columns=[\"tags\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5af4d270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>completeness</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>relevance</th>\n",
       "      <th>recall_final</th>\n",
       "      <th>recall_total</th>\n",
       "      <th>total_retrived_entities</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ques_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>row-level</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>23.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structural</th>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.421296</td>\n",
       "      <td>0.62037</td>\n",
       "      <td>10.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            completeness  accuracy  relevance  recall_final  recall_total  \\\n",
       "ques_type                                                                   \n",
       "row-level       0.800000  0.800000   0.825000      0.500000       0.50000   \n",
       "structural      0.644444  0.655556   0.611111      0.421296       0.62037   \n",
       "\n",
       "            total_retrived_entities  \n",
       "ques_type                            \n",
       "row-level                 23.500000  \n",
       "structural                10.888889  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_res_df.groupby(\"ques_type\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978051e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
